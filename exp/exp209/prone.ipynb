{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8efcce1a-165a-4a5b-aa5b-1b0d0c4a23c1",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c076122-4690-4781-a486-e699bed02d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Union\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from annoy import AnnoyIndex\n",
    "import polars as pl\n",
    "import networkx as nx\n",
    "import scipy.sparse\n",
    "import scipy.sparse as sp\n",
    "from scipy import linalg\n",
    "from scipy.special import iv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "import polars as pl\n",
    "\n",
    "from scripts.metrics import map_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "298c78ad-edda-49c1-a972-842d08660152",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"../../input/raw/\"\n",
    "OUTPUT_DIR = \"./candidates/\"\n",
    "\n",
    "TOP_N = 10\n",
    "\n",
    "# hyper-parameter for proNE\n",
    "EMB_DIM = 2048\n",
    "N_EPOCH = 10\n",
    "MU = 0\n",
    "THETA = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f51f82be-de47-4828-a787-cf6df7be48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_and_add_seq_no(df:pl.DataFrame) -> pl.DataFrame:\n",
    "    df = df.explode([\"prev_items\"])\n",
    "    df = df.with_columns(\n",
    "        df.select(pl.col(\"session_id\").cumcount().over(\"session_id\").alias(\"seq_no\").cast(pl.Int64))\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9032296d-3a14-43a6-999f-643549dfc3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(df:pl.DataFrame):\n",
    "    df = df.sort([\"session_id\", \"seq_no\"], descending=[False, False])\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"item\").shift().over(\"session_id\").alias(\"prev_item\")\n",
    "    )\n",
    "    df = df.filter(\n",
    "        (pl.col(\"prev_item\").is_not_null()) &\n",
    "        (pl.col(\"prev_item\") != pl.col(\"item\"))\n",
    "    )\n",
    "    df = df[[\"item\", \"prev_item\"]]\n",
    "    # df = df.unique()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110d1ec4-58e0-4e34-b7f2-bb0c5200e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_item_id(df:pl.DataFrame):\n",
    "    unique_item_ids = sorted(list(set(df[\"item\"].unique().to_list() + df[\"prev_item\"].unique().to_list())))\n",
    "    item_id2index = dict(zip(unique_item_ids, range(len(unique_item_ids))))\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"item\").map_dict(item_id2index).alias(\"item\"),\n",
    "        pl.col(\"prev_item\").map_dict(item_id2index).alias(\"prev_item\"),\n",
    "    ])\n",
    "    return df, unique_item_ids, item_id2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f3baa48-c0c7-4613-a079-acf017b1ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/THUDM/ProNE/blob/master/proNE.py\n",
    "class ProNE():\n",
    "\tdef __init__(self, graph_file, emb_file1, emb_file2, dimension):\n",
    "\t\tself.graph = graph_file\n",
    "\t\tself.emb1 = emb_file1\n",
    "\t\tself.emb2 = emb_file2\n",
    "\t\tself.dimension = dimension\n",
    "\n",
    "\t\tself.G = nx.read_edgelist(self.graph, nodetype=int, create_using=nx.DiGraph())\n",
    "\t\tself.G = self.G.to_undirected()\n",
    "\t\tself.node_number = self.G.number_of_nodes()\n",
    "\t\tmatrix0 = scipy.sparse.lil_matrix((self.node_number, self.node_number))\n",
    "\n",
    "\t\tfor e in self.G.edges():\n",
    "\t\t\tif e[0] != e[1]:\n",
    "\t\t\t\tmatrix0[e[0], e[1]] = 1\n",
    "\t\t\t\tmatrix0[e[1], e[0]] = 1\n",
    "\t\tself.matrix0 = scipy.sparse.csr_matrix(matrix0)\n",
    "\t\tprint(matrix0.shape)\n",
    "\n",
    "\tdef get_embedding_rand(self, matrix):\n",
    "\t\t# Sparse randomized tSVD for fast embedding\n",
    "\t\tt1 = time.time()\n",
    "\t\tl = matrix.shape[0]\n",
    "\t\tsmat = scipy.sparse.csc_matrix(matrix)  # convert to sparse CSC format\n",
    "\t\tprint('svd sparse', smat.data.shape[0] * 1.0 / l ** 2)\n",
    "\t\tU, Sigma, VT = randomized_svd(smat, n_components=self.dimension, n_iter=5, random_state=None)\n",
    "\t\tU = U * np.sqrt(Sigma)\n",
    "\t\tU = preprocessing.normalize(U, \"l2\")\n",
    "\t\tprint('sparsesvd time', time.time() - t1)\n",
    "\t\treturn U\n",
    "\n",
    "\tdef get_embedding_dense(self, matrix, dimension):\n",
    "\t\t# get dense embedding via SVD\n",
    "\t\tt1 = time.time()\n",
    "\t\tU, s, Vh = linalg.svd(matrix, full_matrices=False, check_finite=False, overwrite_a=True)\n",
    "\t\tU = np.array(U)\n",
    "\t\tU = U[:, :dimension]\n",
    "\t\ts = s[:dimension]\n",
    "\t\ts = np.sqrt(s)\n",
    "\t\tU = U * s\n",
    "\t\tU = preprocessing.normalize(U, \"l2\")\n",
    "\t\tprint('densesvd time', time.time() - t1)\n",
    "\t\treturn U\n",
    "\n",
    "\tdef pre_factorization(self, tran, mask):\n",
    "\t\t# Network Embedding as Sparse Matrix Factorization\n",
    "\t\tt1 = time.time()\n",
    "\t\tl1 = 0.75\n",
    "\t\tC1 = preprocessing.normalize(tran, \"l1\")\n",
    "\t\tneg = np.array(C1.sum(axis=0))[0] ** l1\n",
    "\n",
    "\t\tneg = neg / neg.sum()\n",
    "\n",
    "\t\tneg = scipy.sparse.diags(neg, format=\"csr\")\n",
    "\t\tneg = mask.dot(neg)\n",
    "\t\tprint(\"neg\", time.time() - t1)\n",
    "\n",
    "\t\tC1.data[C1.data <= 0] = 1\n",
    "\t\tneg.data[neg.data <= 0] = 1\n",
    "\n",
    "\t\tC1.data = np.log(C1.data)\n",
    "\t\tneg.data = np.log(neg.data)\n",
    "\n",
    "\t\tC1 -= neg\n",
    "\t\tF = C1\n",
    "\t\tfeatures_matrix = self.get_embedding_rand(F)\n",
    "\t\treturn features_matrix\n",
    "\n",
    "\tdef chebyshev_gaussian(self, A, a, order=10, mu=0.5, s=0.5):\n",
    "\t\t# NE Enhancement via Spectral Propagation\n",
    "\t\tprint('Chebyshev Series -----------------')\n",
    "\t\tt1 = time.time()\n",
    "\n",
    "\t\tif order == 1:\n",
    "\t\t\treturn a\n",
    "\n",
    "\t\tA = sp.eye(self.node_number) + A\n",
    "\t\tDA = preprocessing.normalize(A, norm='l1')\n",
    "\t\tL = sp.eye(self.node_number) - DA\n",
    "\n",
    "\t\tM = L - mu * sp.eye(self.node_number)\n",
    "\n",
    "\t\tLx0 = a\n",
    "\t\tLx1 = M.dot(a)\n",
    "\t\tLx1 = 0.5 * M.dot(Lx1) - a\n",
    "\n",
    "\t\tconv = iv(0, s) * Lx0\n",
    "\t\tconv -= 2 * iv(1, s) * Lx1\n",
    "\t\tfor i in range(2, order):\n",
    "\t\t\tLx2 = M.dot(Lx1)\n",
    "\t\t\tLx2 = (M.dot(Lx2) - 2 * Lx1) - Lx0\n",
    "\t\t\t#         Lx2 = 2*L.dot(Lx1) - Lx0\n",
    "\t\t\tif i % 2 == 0:\n",
    "\t\t\t\tconv += 2 * iv(i, s) * Lx2\n",
    "\t\t\telse:\n",
    "\t\t\t\tconv -= 2 * iv(i, s) * Lx2\n",
    "\t\t\tLx0 = Lx1\n",
    "\t\t\tLx1 = Lx2\n",
    "\t\t\tdel Lx2\n",
    "\t\t\tprint('Bessell time', i, time.time() - t1)\n",
    "\t\tmm = A.dot(a - conv)\n",
    "\t\temb = self.get_embedding_dense(mm, self.dimension)\n",
    "\t\treturn emb\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "994d3b3a-f48b-4a2e-8132-6a27e8d7a8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/THUDM/ProNE/blob/master/proNE.py\n",
    "def save_embedding(emb_file, features):\n",
    "\t# save node embedding into emb_file with word2vec format\n",
    "\tf_emb = open(emb_file, 'w')\n",
    "\tf_emb.write(str(len(features)) + \" \" + str(features.shape[1]) + \"\\n\")\n",
    "\tfor i in range(len(features)):\n",
    "\t\ts = str(i) + \" \" + \" \".join(str(f) for f in features[i].tolist())\n",
    "\t\tf_emb.write(s + \"\\n\")\n",
    "\tf_emb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbdc2e13-5caa-47d7-aa3d-677c2c73bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_annoy_index(matrix):\n",
    "    index = AnnoyIndex(EMB_DIM, 'angular')\n",
    "\n",
    "    for idx,idx_embedding in enumerate(matrix):\n",
    "        index.add_item(idx, idx_embedding)\n",
    "        \n",
    "    index.build(50)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9829cc30-ce12-4b56-b9a6-84adbbc9ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nns_matrix(annoy_index, item_ids, item_id2index, k=100):\n",
    "    aid_xs = []\n",
    "    aid_ys = []\n",
    "    dists = []\n",
    "\n",
    "    for item_id in tqdm(item_ids):\n",
    "        item_index = item_id2index[item_id]\n",
    "        nns = annoy_index.get_nns_by_item(item_index, k+1, include_distances=True)\n",
    "        aid_y = [item_ids[idx] for idx in list(nns[0][1:])]\n",
    "        dist = list(nns[1][1:])\n",
    "        aid_xs.extend([item_id] * k)\n",
    "        aid_ys.extend(aid_y)\n",
    "        dists.extend(dist)\n",
    "    df = pl.DataFrame({\"yad_no\": aid_xs, 'candidate_yad_no': aid_ys, 'prone_distance': dists})\n",
    "\n",
    "    # rankを計算\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"prone_distance\").rank(descending=False).over(\"yad_no\").alias(\"prone_rank\")\n",
    "    ).drop(\"prone_distance\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491659c0-7e69-471e-96eb-451c0575d045",
   "metadata": {},
   "source": [
    "# For local train/eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e35acd2-91b7-4301-823d-65c3593b0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = pl.read_csv(os.path.join(INPUT_DIR, \"train_log.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99464342-351c-4ec6-a224-fac1a281c4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = train_log.rename({\"yad_no\":\"item\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea78b085-758d-4af5-8748-9b6ae89c9b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11129, 11129)\n",
      "neg 0.0034699440002441406\n",
      "svd sparse 0.0007288705475316019\n",
      "sparsesvd time 19.143075704574585\n",
      "Chebyshev Series -----------------\n",
      "Bessell time 2 1.537233829498291\n",
      "Bessell time 3 2.3204243183135986\n",
      "Bessell time 4 3.1019134521484375\n",
      "Bessell time 5 3.8930490016937256\n",
      "Bessell time 6 4.683181047439575\n",
      "Bessell time 7 5.452115058898926\n",
      "Bessell time 8 6.215810060501099\n",
      "Bessell time 9 7.059511184692383\n",
      "densesvd time 5.261455774307251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 11129/11129 [00:14<00:00, 751.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# build graph\n",
    "graph_df = build_graph(train_log)\n",
    "graph_df, item_ids, item_id2index = convert_item_id(graph_df)\n",
    "graph_df.write_csv(\"features/edge_list_for_train_or_eval.txt\", has_header=False, separator=\" \")\n",
    "item_ids_name = \"graph_item_id2index_for_train_or_eval.pickle\"\n",
    "with open(\"features/\" + item_ids_name, \"wb\") as f:\n",
    "    pickle.dump(item_id2index, f)\n",
    "\n",
    "# generate graph embedding by proNE \n",
    "model = ProNE(\n",
    "    \"features/edge_list_for_train_or_eval.txt\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    EMB_DIM,\n",
    ")\n",
    "features_matrix = model.pre_factorization(model.matrix0, model.matrix0)\n",
    "embeddings_matrix = model.chebyshev_gaussian(model.matrix0, features_matrix, N_EPOCH, MU, THETA)\n",
    "np.save(\"features/graph_embedding_for_train_or_eval.npy\", embeddings_matrix)\n",
    "\n",
    "# generate_candidates\n",
    "annoy_index = generate_annoy_index(embeddings_matrix)\n",
    "candidate = make_nns_matrix(annoy_index, item_ids, item_id2index, k=TOP_N)\n",
    "candidate.write_parquet(\"candidates/prone_for_train_or_eval.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6689bc3f-daeb-40fe-81da-19a3dcd407c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>yad_no</th><th>candidate_yad_no</th><th>prone_rank</th></tr><tr><td>i64</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>2</td><td>3860</td><td>1.5</td></tr><tr><td>2</td><td>13783</td><td>1.5</td></tr><tr><td>2</td><td>12162</td><td>3.0</td></tr><tr><td>2</td><td>299</td><td>4.0</td></tr><tr><td>2</td><td>3847</td><td>5.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌────────┬──────────────────┬────────────┐\n",
       "│ yad_no ┆ candidate_yad_no ┆ prone_rank │\n",
       "│ ---    ┆ ---              ┆ ---        │\n",
       "│ i64    ┆ i64              ┆ f64        │\n",
       "╞════════╪══════════════════╪════════════╡\n",
       "│ 2      ┆ 3860             ┆ 1.5        │\n",
       "│ 2      ┆ 13783            ┆ 1.5        │\n",
       "│ 2      ┆ 12162            ┆ 3.0        │\n",
       "│ 2      ┆ 299              ┆ 4.0        │\n",
       "│ 2      ┆ 3847             ┆ 5.0        │\n",
       "└────────┴──────────────────┴────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1951dcac-0337-46f7-afd2-23f12afe6fdb",
   "metadata": {},
   "source": [
    "# MAP@k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99b9bacc-af08-4a3c-aa0a-34e38016ec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = pl.read_csv(os.path.join(INPUT_DIR, \"train_log.csv\"))\n",
    "train_label = pl.read_csv(os.path.join(INPUT_DIR, \"train_label.csv\")).rename({\"yad_no\":\"label_yad_no\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7e1eb11-448e-4e0b-887c-25845e1589d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_items = train_log.group_by(\"session_id\").last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3475109c-84cd-4b4d-a059-274e0cd673a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_visit_matrix = pl.read_parquet(os.path.join(OUTPUT_DIR, \"prone_for_train_or_eval.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2029228f-9bc1-489d-a291-7dfdf344d4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = last_items \\\n",
    "    .join(co_visit_matrix, on=\"yad_no\", how=\"left\") \\\n",
    "    .join(train_label, on=\"session_id\", how=\"left\") \\\n",
    "    .sort([\"session_id\", \"prone_rank\"], descending=[False, False]) \\\n",
    "    .with_columns((pl.col(\"candidate_yad_no\") == pl.col(\"label_yad_no\")).cast(pl.Int8).alias(\"user_relevance\")) \\\n",
    "    .fill_null(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5ca022a-2984-42ce-8cbd-eb426c7cf081",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_relevances = prediction.group_by(\"session_id\", maintain_order=True).all()[\"user_relevance\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dce91a9c-e67a-4f9b-8251-8825d4d8ed44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16303999554870707"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_at_k(user_relevances, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38d2dcb-d08b-4512-ae8c-99b312cd17cc",
   "metadata": {},
   "source": [
    "# For test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12e7ced3-7de2-401b-b45c-e64363dcd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_log = pl.read_csv(os.path.join(INPUT_DIR, \"train_log.csv\"))\n",
    "train_label = pl.read_csv(os.path.join(INPUT_DIR, \"train_label.csv\"))\n",
    "test_log = pl.read_csv(os.path.join(INPUT_DIR, \"test_log.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75b51fba-138e-4dff-8ad5-f1224105496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainのlabelをlogにappendする\n",
    "\n",
    "prev_items_list = (\n",
    "    train_log\n",
    "    .sort([\"session_id\", \"seq_no\"])\n",
    "    .group_by(\"session_id\", maintain_order=True)\n",
    "    .agg(pl.col(\"yad_no\"))\n",
    ")[\"yad_no\"].to_list()\n",
    "\n",
    "next_item_list = (\n",
    "    train_label\n",
    "    .sort(\"session_id\")\n",
    ")[\"yad_no\"].to_list()\n",
    "\n",
    "prev_items_list_updated = []\n",
    "for prev_items, next_item in zip(prev_items_list, next_item_list):\n",
    "    prev_items.append(next_item)\n",
    "    prev_items_list_updated.append(prev_items)\n",
    "\n",
    "train_log = train_label.with_columns(\n",
    "    pl.Series(name=\"prev_items\", values=prev_items_list_updated)\n",
    ")\n",
    "\n",
    "train_log = explode_and_add_seq_no(train_log) \\\n",
    "    .drop(\"yad_no\") \\\n",
    "    .rename({\"prev_items\" : \"yad_no\"}) \\\n",
    "    [[\"session_id\", \"seq_no\", \"yad_no\"]] # カラム並び替え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64da6c2d-7b3c-4a09-84f7-75607af7b11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pl.concat([train_log, test_log], how=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9707392-d0a6-4dc0-8535-26b8a1477249",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = log.rename({\"yad_no\":\"item\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63d9b3c9-079f-42ee-9638-58e8fecb647d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13806, 13806)\n",
      "neg 0.005507707595825195\n",
      "svd sparse 0.0013272010487664699\n",
      "sparsesvd time 30.785429000854492\n",
      "Chebyshev Series -----------------\n",
      "Bessell time 2 2.8797013759613037\n",
      "Bessell time 3 4.341245651245117\n",
      "Bessell time 4 5.8141913414001465\n",
      "Bessell time 5 7.27593994140625\n",
      "Bessell time 6 8.754674196243286\n",
      "Bessell time 7 10.24494743347168\n",
      "Bessell time 8 11.697623014450073\n",
      "Bessell time 9 13.153645038604736\n",
      "densesvd time 6.757952928543091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 13806/13806 [00:22<00:00, 613.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# build graph\n",
    "graph_df = build_graph(log)\n",
    "graph_df, item_ids, item_id2index = convert_item_id(graph_df)\n",
    "graph_df.write_csv(\"features/edge_list_for_test.txt\", has_header=False, separator=\" \")\n",
    "item_ids_name = \"graph_item_id2index_for_test.pickle\"\n",
    "with open(\"features/\" + item_ids_name, \"wb\") as f:\n",
    "    pickle.dump(item_id2index, f)\n",
    "\n",
    "# generate graph embedding by proNE \n",
    "model = ProNE(\n",
    "    \"features/edge_list_for_test.txt\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    EMB_DIM,\n",
    ")\n",
    "features_matrix = model.pre_factorization(model.matrix0, model.matrix0)\n",
    "embeddings_matrix = model.chebyshev_gaussian(model.matrix0, features_matrix, N_EPOCH, MU, THETA)\n",
    "np.save(\"features/graph_embedding_for_test.npy\", embeddings_matrix)\n",
    "\n",
    "# generate_candidates\n",
    "annoy_index = generate_annoy_index(embeddings_matrix)\n",
    "candidate = make_nns_matrix(annoy_index, item_ids, item_id2index, k=TOP_N)\n",
    "candidate.write_parquet(\"candidates/prone_for_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a095b5-73e4-4137-a0ff-d599adbdd2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
